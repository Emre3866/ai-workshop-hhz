{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Prices Data Set\n",
    "\n",
    "Create a regression model to predict house prices. See https://www.kaggle.com/camnugent/california-housing-prices for data understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the file\n",
    "my_file = project.get_file(\"housing.csv\")\n",
    "\n",
    "# Read the CSV data file from the object storage into a pandas DataFrame\n",
    "my_file.seek(0)\n",
    "original_data = pd.read_csv(my_file)\n",
    "\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.describe(include='all') # descriptive statistics for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.isnull().sum() # check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data[original_data.duplicated(keep=False)] # check for duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates but missing values for \"total_bedrooms\". Decide what to do with these null values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_null = # your code\n",
    "data_wo_null.isnull().sum() # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung \n",
    "data_wo_null = original_data.dropna(axis=0)\n",
    "data_wo_null.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a correlation map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "f,ax=plt.subplots(figsize = (18,18))\n",
    "sns.heatmap(data_wo_null.corr(),annot= True,linewidths=0.5,fmt = \".1f\",ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlation Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove redundant features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduced_features = data_wo_null[['<your feature 1>', '<your feature 2>','...']]\n",
    "data_reduced_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "data_reduced_features = data_wo_null[['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'median_income', \n",
    "                                      'median_house_value', 'ocean_proximity']] \n",
    "                                        # either keep longitude and latitude or remove both\n",
    "data_reduced_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "The next step is to detect outliers and handle them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduced_features.hist(figsize=(25,25), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = # your code\n",
    "\n",
    "data_reduced_features_2 = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung, total_rooms only, more outliers might be removed! \n",
    "q = data_reduced_features['total_rooms'].quantile(0.99)\n",
    "data_reduced_features_2 = data_reduced_features[data_reduced_features['total_rooms']<q]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modeling\n",
    "\n",
    "Get dummies since there is a categorical feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = # your code\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "dummies = pd.get_dummies(data_reduced_features_2, drop_first=True)\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set X and y (predictors and target) according to your dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dummies['<your target column>']\n",
    "predictors = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "target = dummies['median_house_value']\n",
    "predictors = dummies.drop(['median_house_value'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=123) # 80-20 split into training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use StandardScaler to scale your predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = # your code \n",
    "# your code\n",
    "\n",
    "X_train = # your code\n",
    "X_test = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model and evaluation\n",
    "\n",
    "Create a linear regression model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training performance')\n",
    "print(reg.score(X_train,y_train))\n",
    "print('test performance')\n",
    "print(reg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "test = pd.DataFrame({'Predicted':y_pred,'Actual':y_test})\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "test = test.reset_index()\n",
    "test = test.drop(['index'],axis=1)\n",
    "plt.plot(test[:50])\n",
    "plt.legend(['Actual','Predicted'])\n",
    "sns.jointplot(x='Actual',y='Predicted',data=test,kind='reg',);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the result and feel free to try out further analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musterlösung\n",
    "Training and test performance similar (= no overfitting)\n",
    "simple linear regression model seems to be ok\n",
    "cf. https://people.duke.edu/~rnau/rsquared.htm if you are interested in learning more about evaluating regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the linear regression model via the _Watson Machine Learning_ (WML) service on IBM Cloud. Please refer to the documentation for more details about the [watson-machine-learning-client](https://pypi.org/project/watson-machine-learning-client/) or the [REST API](https://watson-ml-api.mybluemix.net/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Watson Machine Learning Python client library\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in your credentials\n",
    "wml_credentials = {\n",
    "    # your code\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the client\n",
    "wml_client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review stored artifacts\n",
    "wml_client.repository.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete artifacts that are no longer needed (note that the number of stored artifacts in the free version is limited to 5)\n",
    "wml_client.repository.delete(\"...GUID...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in metadata for your deployment\n",
    "metadata = {\n",
    "        wml_client.repository.ModelMetaNames.NAME: 'Housing Prices Deployment',\n",
    "        wml_client.repository.ModelMetaNames.DESCRIPTION: 'Test deployment for the california housing prices data set.',\n",
    "        wml_client.repository.ModelMetaNames.AUTHOR_NAME: 'Your Name'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the (scikit-learn) model in WML\n",
    "stored_model = wml_client.repository.store_model(reg, meta_props=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the id of the stored model\n",
    "published_model_uid = wml_client.repository.get_model_uid(stored_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create deployment and fetch scoring endpoint\n",
    "created_deployment = wml_client.deployments.create(published_model_uid, name=\"Housing Prices Deployment\")\n",
    "scoring_endpoint = wml_client.deployments.get_scoring_url(created_deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the stored deployment to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review test data\n",
    "X_test[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scoring payload\n",
    "scoring_values = X_test[0:2].tolist()\n",
    "scoring_payload = {\"values\": scoring_values}\n",
    "print(scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction\n",
    "predictions = wml_client.deployments.score(scoring_endpoint, scoring_payload)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the results match your expectation? Are the estimations accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the local model to make the same prediction in your notebook and compare the results\n",
    "reg.predict(X_test[0:2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
